{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building word2vec model using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Hridaya\n",
      "[nltk_data]     Pradhan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#data processing\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopWords = stopwords.words('english')\n",
    "\n",
    "#modelling\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>room kind clean strong smell dogs. generally a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stayed crown plaza april april . staff friendl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>booked hotel hotwire lowest price could find. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stayed husband sons way alaska cruise. loved h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>girlfriends stayed celebrate th birthdays. pla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  room kind clean strong smell dogs. generally a...\n",
       "1  stayed crown plaza april april . staff friendl...\n",
       "2  booked hotel hotwire lowest price could find. ...\n",
       "3  stayed husband sons way alaska cruise. loved h...\n",
       "4  girlfriends stayed celebrate th birthdays. pla..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('data/text.csv',header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'agree fancy. everything needed. breakfast pool hot tub nice shuttle airport later checkout time. noise issue tough sleep through. awhile forget noisy door nearby noisy guests. complained management later email credit compd us amount requested would return.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess and prepare data\n",
    "def pre_process(text):\n",
    "    \n",
    "    #convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    #remove all special characters and keep only alpha numeric characters and spaces\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s.]',r'',text)\n",
    "    \n",
    "    #remove new lines\n",
    "    text = re.sub(r'\\n',r' ',text)\n",
    "    \n",
    "    # remove stop words\n",
    "    text = \" \".join([word for word in text.split() if word not in stopWords])\n",
    "    \n",
    "    return text\n",
    "\n",
    "pre_process(data[0][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    room kind clean strong smell dogs. generally a...\n",
       "1    stayed crown plaza april april . staff friendl...\n",
       "2    booked hotel hotwire lowest price could find. ...\n",
       "3    stayed husband sons way alaska cruise. loved h...\n",
       "4    girlfriends stayed celebrate th birthdays. pla...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] = data[0].map(lambda x: pre_process(x))\n",
    "data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stayed crown plaza april april ',\n",
       " ' staff friendly attentive',\n",
       " ' elevators tiny ',\n",
       " ' food restaurant delicious priced little high side',\n",
       " ' course washington dc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][1].split('.')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['stayed', 'crown', 'plaza', 'april', 'april'],\n",
       " ['staff', 'friendly', 'attentive']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for line in data[0][1].split('.'):\n",
    "    words = [x for x in line.split()]\n",
    "    corpus.append(words)\n",
    "\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['room', 'kind', 'clean', 'strong', 'smell', 'dogs'],\n",
       " ['generally', 'average', 'ok', 'overnight', 'stay', 'youre', 'fussy']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[0].map(lambda x: x.split('.'))\n",
    "\n",
    "corpus = []\n",
    "for i in (range(len(data))):\n",
    "    for line in data[i]:\n",
    "        words = [x for x in line.split()]\n",
    "        corpus.append(words)\n",
    "\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['connected', 'rivercenter', 'mall', 'downtown', 'san_antonio']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = Phrases(sentences=corpus,min_count=25,threshold=50)\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "for index,sentence in enumerate(corpus):\n",
    "    corpus[index] = bigram[sentence]\n",
    "\n",
    "corpus[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['course', 'washington_dc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build model\n",
    "size = 100  # Word vector size\n",
    "window_size = 2\n",
    "epochs = 100\n",
    "min_count = 2\n",
    "workers = 4\n",
    "sg = 1\n",
    "\n",
    "model = Word2Vec(corpus, sg=sg, window=window_size, vector_size=size, \n",
    "                 min_count=min_count, workers=workers, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/word2vec.model')\n",
    "model = Word2Vec.load('model/word2vec.model')\n",
    "model = Word2Vec.load('model/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('san_antonio', 0.7854580879211426),\n",
       " ('san_francisco', 0.7668282389640808),\n",
       " ('phoenix', 0.7567591071128845),\n",
       " ('memphis', 0.7417790293693542),\n",
       " ('austin', 0.7309386730194092),\n",
       " ('dallas', 0.7235692143440247),\n",
       " ('indianapolis', 0.7212599515914917),\n",
       " ('la', 0.7203453183174133),\n",
       " ('boston', 0.7128455638885498),\n",
       " ('sf', 0.7112388610839844)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate embeddings\n",
    "model.wv.most_similar('san_diego')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6996163725852966)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'holiday'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['los_angeles','indianapolis', 'holiday', 'san_antonio','new_york']\n",
    "\n",
    "model.wv.doesnt_match(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing word embeddings with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"model/word2vec.model\"\n",
    "model = gensim.models.keyedvectors.KeyedVectors.load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = len(model.wv.index_to_key)\n",
    "w2v = np.zeros((max_size, model.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:An interactive session is already active. This can cause out-of-memory errors or some other unexpected errors (due to the unpredictable timing of garbage collection) in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s). Please use `tf.Session()` if you intend to productionize.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('projections'):\n",
    "    os.makedirs('projections')\n",
    "    \n",
    "with open(\"projections/metadata.tsv\", 'w+') as file_metadata:\n",
    "    \n",
    "    for i, word in enumerate(model.wv.index_to_key[:max_size]):\n",
    "        \n",
    "        #store the embeddings of the word\n",
    "        w2v[i] = model.wv[word]\n",
    "        \n",
    "        #write the word to a file \n",
    "        file_metadata.write(word + '\\n')\n",
    "        \n",
    "sess = tf.compat.v1.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.compat.v1.Variable(w2v, trainable=False, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.compat.v1.summary.FileWriter('projections', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = projector.ProjectorConfig()\n",
    "embed= config.embeddings.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.tensor_name = 'embedding'\n",
    "embed.metadata_path = 'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projections/model.ckpt-28071'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projector.visualize_embeddings(writer, config)\n",
    "\n",
    "saver.save(sess, 'projections/model.ckpt', global_step=max_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
